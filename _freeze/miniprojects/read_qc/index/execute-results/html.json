{
  "hash": "d2ee8a021ce682ee07020039113a293a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\nauthor: \"Ryan M. Moore, PhD\"\ndate-modified: last-modified\ndate: \"2025-04-30\"\njupyter: python3\n---\n\n# Miniproject 3: Read Quality Control {.unnumbered}\n\n_Note: To complete the miniproject, you will need the material contained in the [Read QC project files directory](https://github.com/mooreryan/applied_python_programming/blob/main/miniprojects/read_qc/project_files). There, you will find a project scaffold that includes reads, `lib.py`, and quarto documents to help get you started. The page you are currently reading is the same as [miniproject_3_instructions.qmd](https://github.com/mooreryan/applied_python_programming/blob/main/miniprojects/read_qc/project_files/miniproject_3_instructions.qmd) in the previously linked directory._\n\n## Overview\n\nFor your final miniproject, you'll perform quality control analysis on next-generation sequencing (NGS) reads. This is a common first step in any (meta)genomics or RNA-seq pipeline. You'll gain experience working with FASTQ files, calculating quality metrics, and filtering reads based on quality thresholds.\n\nThe provided sequencing data comes from a hypothetical, multi-hospital RNA-seq study with different batches of samples and experimental conditions. Your task is to analyze this data to identify trends in read quality and to filter low-quality reads.\n\n_Note: This is the final project, so it will be a bit of a jump in complexity! The instruction document has a ton of info to help you out, and the book chapters and assignment 3 will also be helpful. Be sure to refer to them if you get stuck!_\n\n## Learning Objectives\n\nBy completing this miniproject, you will:\n\n- Work with sequencing data in FASTQ format\n- Parse and manipulate gzip-compressed files\n- Calculate quality metrics for sequencing reads\n- Visualize quality distributions by different variables\n- Implement a read filtering strategy\n- Practice modular Python programming\n\n## Data Info\n\n### Input Files\n\n- **FASTQ Files**\n    - Located in the `reads/` directory.\n    - These files contain raw sequencing reads with the naming pattern `[LOCATION]_[CONDITION][NUMBER].fq.gz`.\n- **Metadata**\n    - A tab-separated file `metadata.tsv` containing sample information.\n    - Fields\n        - **SampleID**: Unique identifier for each sample, including a prefix indicating the location (e.g., CHR for Christiana Hospital) and a suffix indicating the condition (C for Control, T for Treatment) with a number.\n        - **PatientID**: Alphanumeric identifier for each patient (e.g., 0626, 5542, 26ED).\n        - **Batch**: Batch designation, either A or B, which groups samples processed and sequenced together.\n        - **Location**: Healthcare facility where the sample was collected (Christiana Hospital, Nemours Children's Hospital, Jefferson Hospital, or Bayhealth Medical Center).\n        - **Condition**: Experimental condition of the sample, either \"Control\" or \"Treatment\".\n\n### FASTQ Format Reminder\n\nEach read in a FASTQ file consists of four lines:\n\n1. Read identifier (starts with `@`)\n2. Nucleotide sequence\n3. `+` (sometimes followed by the identifier again, or other info)\n4. Phred quality scores (encoded as ASCII characters)\n\n_See [parsing FASTQ files](https://pythonforlifescientists.com/io_files_contexts/#fastq) and the [processing FASTQ files](https://pythonforlifescientists.com/io_files_contexts/#example-processing-fastq-files) example from Ch. 9 for more info._\n\n### Project Structure\n\nYou have been provided a zipped directory with the following structure:\n\n```\nminiproject_3/\n├── lib.py\n├── metadata.tsv\n├── miniproject_3_instructions.qmd\n├── miniproject_3_solution.qmd\n└── reads\n    ├── BAY_C1.fq.gz\n    ├── BAY_C2.fq.gz\n    ├── ... (more read files)\n```\n\nFor this project, you'll be working with multiple files:\n\n- `miniproject_3_solution.qmd`: The main Quarto document where you'll perform your analysis and write up your results\n- `lib.py`: A Python module containing helper functions that you will write.\n    - The functions and other stuff you need to include in this file will be described in below.\n    - All of these functions should have docstrings in the format we described in [Ch. 4](https://pythonforlifescientists.com/understanding_functions/#sec-function-docs).\n\n## Your Tasks\n\nThis miniproject consists of three parts: two required, one optional.\n\n### Set Up\n\nYou will need the following set up code near the top of your Quarto document.\n\n```python\nimport gzip\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom Bio import SeqIO\nfrom statsmodels.formula.api import ols\n\n# This is our module defined in lib.py\nimport lib\n\npd.set_option(\"display.max_rows\", 6)\n```\n\nAdditionally, when you need to edit your `lib.py` file, you will have to manually reload the module. (Or restart the Quarto interactive prompt.)  Here is how you can do that:\n\n```python\nimport importlib\nimportlib.reload(lib)\n```\n\n_Note: I have already included the above code blocks in the solution file for you!_\n\n### Part 1: Basic Read Quality Analysis __(Required)__\n\nIn this section, you'll parse the FASTQ files, calculate quality metrics for all samples, and analyze how these metrics vary across different experimental factors.\n\n#### Part 1A: Parse FASTQ Files\n\nHere are the steps you will need to take. I've written it in a sort of pseudocode (`:=` means assign to a variable, and `#` are comments) that you can use to help you structure your own code:\n\n```\n# Find all the FASTQ files in the reads directory that match our pattern\n# This uses Path.glob() to get files with names ending in _T1.fq.gz, _T2.fq.gz, etc.\npaths := get the FASTQ file paths\n\n# Create an empty list to store our processed read information\n# Each element will be a ReadInfo object with metadata about a sequence read\nreads := empty list\n\n# Process each FASTQ file\nfor each path in paths\n    # Extract the sample name from the filename\n    # This helps us track which experiment/condition each read came from\n    sample_id := get the sample ID from the path\n\n    # Open and read the compressed FASTQ file\n    # Note: gzipped files require special handling with gzip.open()\n    # We need to open in text mode (\"rt\") for Bio.SeqIO to parse correctly\n    open the gzipped file for text-reading:\n        # Parse each sequence record in the FASTQ file\n        # SeqIO.parse creates an iterator of SeqRecord objects\n        for each record in the parsed FASTQ file:\n            # Create a structured ReadInfo object with metrics we care about\n            # We calculate quality score and GC content for each read\n            read_info := create a ReadInfo object from the sample and record\n\n            # Add this processed Read to our collection\n            append read_info to reads list\n\n# Convert our list of ReadInfo objects to a pandas DataFrame for analysis\n# Sort the data by sample ID for easier comparison between samples\n# Reset the index to have clean, sequential row numbers\nread_data := create a pandas data frame from the reads list,\n             sort values by SampleID,\n             reset the index\n```\n\n##### Details & Hints\n\nThis subsection has quite a few parts! Here are some hints to help you get started.\n\n###### Get All FASTQ File Paths\n\nTry the [pathlib.Path](https://docs.python.org/3/library/pathlib.html) class to get all the FASTQ file paths:\n\n```python\n# Get all FASTQ files in the \"reads\" directory matching a pattern\npaths = Path(\"reads\").glob(\"*_[TC][123].fq.gz\")\n\n# Now you can loop over all the matching paths:\nfor path in paths:\n    # Parsh the gzipped FASTQ file\n    pass\n```\n\n###### Get Sample Name from Path\n\nWhen looping over the paths, you will need to get the sample name from the path.\n\nTo do that, you will need to remove the directory name, and the `.fq.gz` extension. You can use the [pathlib.Path](https://docs.python.org/3/library/pathlib.html) class again. Check out those docs and see if you can figure it out.  Here is a hint:\n\n```python\n# Extract parts of a path\npath.stem  # filename without extension\npath.suffix  # file extension\n```\n\n_Note: If you have multiple extensions, like we do in these files (`BAY_C1.fq.gz`), you will need to remove them _both_: `path.stem` will only remove the `.gz` from the example file._\n\nIn the `lib.py` file, create a function called `sample_id()` that takes a `Path` and returns the name of the sample. E.g., if you had a path like this `Path(\"reads/BAY_C1.fq.gz\")`, this function would return `BAY_C1`.\n\n###### Parsing gzipped FASTQ Files\n\nFor working with [gzip](https://www.gzip.org/) compressed FASTQ files, you'll need to use Python's [gzip](https://docs.python.org/3/library/gzip.html) module. Something like this:\n\n```python\n# \"rt\" mode for text reading\nwith gzip.open(path, \"rt\") as file:\n    for record in SeqIO.parse(file, \"fastq\"):\n        # process each record\n```\n\n###### Converting `SeqRecord` to `ReadInfo`\n\nFor each `SeqRecord` that you get with [`SeqIO.parse()`](https://biopython.org/wiki/SeqIO), you need to convert it into a `ReadInfo` [named tuple](https://pythonforlifescientists.com/collections/#named-tuples).\n\n- In the `lib.py` file, create a named tuple called `ReadInfo` with the following fields:\n    - `SampleID`: The unique identifier for the sample from which the read originated\n    - `QualityScore`: The mean quality score of the read\n    - `GC`: The GC percent of the read\n- Next, in the `lib.py` file create a function called `make_read_info` that takes a sample name and a `SeqRecord` and returns a `ReadInfo`\n    - This will require you to write some additional helper functions:\n        - `def quality_score(seq_record)`: Get the quality scores from a `SeqRecord`\n        - `def mean_quality_score(seq_record)`: Calculate the mean quality score for a `SeqRecord`\n        - `def gc_percent(seq_record)`: Calculate the GC percent for a `SeqRecord`\n    - I know you could write this function without those helpers, but this is my assignment, and I say you have to write the helpers! (*^‿^*)\n\n#### Part 1B: Parse Metadata and Merge with Read Data\n\n- Parse the `metadata.tsv` file and merge the metadata with the read quality information.\n- You can use [pandas.read_csv()](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) for this, but you will have to check out the docs to figure out how to change the delimiter.\n\n#### Part 1C: Quality Distributions by Variable\n\n- Generate KDE distribution plots using [seaborn.displot()](https://seaborn.pydata.org/generated/seaborn.displot.html) for all combinations of read property (Quality Score and GC%) and sample variable (Batch, Location, Condition).  The arguments should be like this:\n    - x-axis: Read property (Quality Score and GC%)\n    - y-axis: Sample variable (Batch, Location, Condition)\n    - fill: true\n    - height: 2\n    - aspect: 2\n- Then, use the plots to answer the following questions:\n    - Which variable is most closely identified with differences in Quality Score?\n    - Which variable is most closely identified with differences in GC Content?\n\n##### Details & Hints\n\nTo create multiple plots with different variables, you can either write each combination out by hand, or you can use a for loop like this:\n\n```python\n# Example of creating plots in a loop\nfor read_property in [\"QualityScore\", \"GC\"]:\n    for variable in [\"Batch\", \"Location\", \"Condition\"]:\n        # Your plot code here...\n```\n\n#### Part 1D: Quality Scores and GC Content for Individual Samples\n\n- Generate box plots with [seaborn.catplot()](https://seaborn.pydata.org/generated/seaborn.catplot.html) for Quality Score and GC Content. Use these arguments:\n    - x-axis: Read property (quality score, GC)\n    - y-axis: SampleID\n    - fill: true\n- Set the `hue` for each plot to the variable that best explains the differences in each read property. (You identified the variables in Part 1C.)\n- Which sample has the lowest average quality scores?\n\n#### Part 1E: Read Counts\n\n- Create a data frame with the number of reads for each sample (hint: you could use [value_counts()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html) for this)\n- Merge the metadata data frame and the read counts data frame\n- Generate read count bar plots for each sample with [seaborn.catplot()](https://seaborn.pydata.org/generated/seaborn.catplot.html). Use these arguments:\n    - x-axis: Read Count\n    - y-axis: SampleID\n    - fill: true\n- Examine the plot to determine which variable is most closely associated with differences in read count across samples\n- Redo the the previous bar plot, but this time set the `hue` to the variable you identified in the previous step\n- Determine if there is a significant difference in read lengths for that variable using ANOVA (use the one from [statsmodels](https://www.statsmodels.org/stable/anova.html) this time)\n- If there is a significant difference run Tukey's HSD and plot the test results results (use the one from [statsmodels](https://www.statsmodels.org/stable/generated/statsmodels.stats.multicomp.pairwise_tukeyhsd.html#statsmodels.stats.multicomp.pairwise_tukeyhsd))\n\n##### Details & Hints\n\nFor analyzing read count differences:\n\n```python\n# ANOVA\nformula = ...\nmodel = ols(formula, data=...).fit()\nanova_result = sm.stats.anova_lm(model, typ=2)\n\n# Tukey's HSD\nresult = sm.stats.multicomp.pairwise_tukeyhsd(\n    ...,\n    groups=...,\n)\n_ = result.plot_simultaneous()\n```\n\n### Part 2: Per-Base Quality Analysis __(Optional)__\n\n_Note: This part is completly optional! You will not be penalized for not attempting it. I suggest you do give it a try though, since we will be making a similar plot to the ones you will have seen in the output of the [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) in your Systems Biology class._\n\nIn this part, you'll examine quality score distributions at each nucleotide position.  Here are the steps:\n\n1. Select a subset of samples representing different conditions (use these `[\"CHR_C1.fq.gz\", \"NEM_C2.fq.gz\", \"JEF_C1.fq.gz\", \"BAY_C3.fq.gz\"]`)\n2. For each sample, extract quality scores at each base position for each read\n3. Create box plots to visualize how quality varies along the length of reads\n\nThis might seem a bit tricky, so let's go over the details. Check out this pseudocode:\n\n```\npaths := join the \"reads\" directory with the four FASTQ files\n\n# Process each FASTQ file\nfor each path in paths:\n    sample_id := get the sample ID from the path\n\n    # Create a list to hold quality scores from all reads in this file\n    quality_scores := empty list\n\n    #  Open and read the compressed FASTQ file\n    open the gzipped file for text-reading:\n        # Extract quality scores from each read\n        for each read in the file:\n            read_qualities := get per-base quality scores from read\n\n            append read_qualities to quality_scores\n\n    # Convert list of quality score lists to numpy matrix\n    quality_matrix := convert quality_scores to numpy matrix\n\n    # Convert numpy matrix to pandas data frame\n    quality_df := convert quality_matrix to pandas data frame\n\n    # Generate box plot\n    create box plot using quality_df showing quality distribution by position\n```\n\nTo join paths, you can use pathlib's [joinpath()](https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.joinpath):\n\n\n```python\npaths = [\n    Path(\"...whatever directory name...\").joinpath(path) for path in [..., ..., ...]\n]\n```\n\nHere is some code to help you get started that converts the list of lists to a numpy matrix, then converts that to the pandas data frame:\n\n```python\n# Convert list of lists to matrix\nquality_data = np.matrix(quality_scores)\n\n# Column names should run from 1 to the length of the reads.\n# You could use `np.arange()` for this.\ncolumn_names = ...\n\n# Convert to DataFrame and reshape\nper_base_quality_scores = (\n    pd.DataFrame(quality_data, columns=...)\n    .melt(\n        var_name=...,\n        value_name=...,\n    )\n    .assign(SampleID=sample)\n)\n```\n\nHere is some code to help you generate the plot:\n\n```python\n# Then make a per-base quality score plot. It has a box plot of score\n# distributions for each base in the set of reads.\nsns.catplot(\n    per_base_quality_scores,\n    kind=...,\n    x=...,\n    y=...,\n    showfliers=False,\n    aspect=2,\n).set(\n    ylim=(0, None),\n    title=...,\n    ylabel=...,\n    xticks=range(4, 100, 5),\n)\n```\n\nMake sure that the title includes the sample ID (e.g., \"XYZ_T1 Per-Base Quality Score\" or something similar).\n\n### Part 3: Quality Filtering __(Required)__\n\nIn this section, you'll implement a read filtering strategy.  For each FASTQ file, you will have to:\n\n- Get the sample name\n- Get the name of the output file\n- Track the total number of reads\n- Track the number of \"good\" reads\n- Check for primer sequences at the start of the reads\n    - If a read starts with one of the two primer sequences, remove that primer sequence from the start of the read\n    - `PRIMER_1 = \"GGTTGTTTCCGCCCAGAGCT\"`\n    - `PRIMER_2 = \"CTTTCTAATGGGCTT\"`\n- Check if a read is of good or bad quality\n    - If it is good, it will be written to the output file\n    - If it is bad, it won't be written to the output file\n- Report the number and percentage of reads that passed filtering for each sample\n\nHere is some more pseudocode to get you started:\n\n```\npaths := xyz\n\nPRIMER_1 := GGTTGTTTCCGCCCAGAGCT\nPRIMER_2 := CTTTCTAATGGGCTT\n\nfor each path in paths:\n    sample := get the name of the sample from the path\n    outfile_name := get the name of the outfile from the path\n\n    total_reads := 0\n    printed_reads := 0\n\n    open the gzipped file for text-reading, and the outfile for writing:\n        for each record in the parsed FASTQ file:\n            total_reads := total_reads + 1\n            record := record with any primers removed\n\n            if the read is good quality:\n                printed_reads := printed_reads + 1\n                write the FASTQ formated record to the outfile\n\n    print the sample_id, total_reads, printed_reads, and percent_printed\n```\n\n\n#### Details & Hints\n\n_Note: There is a similar example in the biopython cookbook called [Simple quality filtering for FASTQ files](https://biopython.org/docs/latest/Tutorial/chapter_cookbook.html#sec-fastq-filtering-example) that you may want to check out as well!_\n\n##### FASTQ Paths\n\nUse the `path.glob` like in part 1 to get all the Paths.\n\n##### Filtered Outfile Name\n\nThis is a bit fiddly, so here is some starter code:\n\n```python\ndef filtered_outfile_name(path):\n    directory = path.resolve().parent\n\n    # Strip off the .fq.gz\n    sample_name = ...\n\n    outfile_name = f\"{sample_name}.filtered.fq\"\n\n    return directory.joinpath(outfile_name)\n```\n\nYou will find this function already in `lib.py`. You will need to complete it before using it.\n\n##### Opening Multiple Files\n\nUse multiple context managers in one `with` statement when you need to open both input and output files simultaneously:\n\n```python\nwith gzip.open(input_path, \"rt\") as infile, open(output_path, \"w\") as outfile:\n    # Process files\n```\n\n##### Removing Primer Sequences\n\nYoyu will implement a simple function to remove primer sequences. There are two possible primer sequences in the reads:\n\n```\nPRIMER_1 = \"GGTTGTTTCCGCCCAGAGCT\"\nPRIMER_2 = \"CTTTCTAATGGGCTT\"\n```\n\n- Not all reads will have primer sequences\n- If a read has a primer sequence, it will only ever be at the _start_ of the read\n- A read will have either 0 or 1 primer sequences (in other words: both primers will never be found in the same read)\n\nWrite a function called `maybe_strip_primer` in `lib.py` that takes a `SeqRecord` and a list of primer sequences.  This function should return a `SeqRecord` with any primer sequences removed, and if no primer sequence is present, the original `SeqRecord` should be returned.\n\n_Note: You can remove reads and quality scores from the beginning of a `SeqRecord` using the normal string slicing notation. See the biopython [cookbook](https://biopython.org/docs/latest/Tutorial/chapter_seq_annot.html#sec-seqrecord-slicing) for details._\n\n_Note: If you remember learning about Illumina sequencing in your other classes, you might think this \"primer trimming\" is a bit weird. Just roll with it!_\n\n##### Checking Read Quality\n\nFor this project, a read is considered low quality if it has 25 or more bases whose Phred quality score is strictly less than 25.\n\nIn the `lib.py` file, write a function called `is_quality_good` that takes a `SeqRecord` and returns a boolean indicating whether the sequence is good quality or not. (Use the `quality_scores` function you defined in Part 1 to help you out.)\n\n## Requirements\n\nYour completed miniproject should include:\n\n1. A Quarto notebook (`miniproject_3_solution.qmd`) with:\n    a. Code for all three parts of the analysis\n    b. Visualizations, interpretations, and discussions of your findings\n    c. Comments explaining your approach\n2. A Python module (`lib.py`) containing helper functions\n\nFollow all the guidelines mentioned above when writing those files!\n\nThe directory structure you should have at the end of the project should look something like this:\n\n```\nminiproject_3_ryan_moore/\n├── lib.py\n├── metadata.tsv\n├── miniproject_3_instructions.qmd\n├── miniproject_3_solution.qmd\n└── reads\n    ├── BAY_C1.filtered.fq\n    ├── BAY_C1.fq.gz\n    ├── BAY_C2.filtered.fq\n    ├── BAY_C2.fq.gz\n    ├── ... (more read files)\n```\n\nYou will need to zip (or tar) that directory and upload the resulting zipped (or tar) file. (You can use `zip` or `tar`, whichever you're most comfortable with.)\n\nPlease don't make additional changes to this structure! You will need to leave the structure as is for me to be able to run your code. If you do not keep the structure as is, and if you do not adjust the top level directory with your name, I will return your project to you without additional comments until you correct it.\n\nAlso, remember that this is a miniproject, so you should be engaging meaningfully with the material and trying to discuss the results you find. Simply writing code with no exposition will not satisfy the requirements for the miniproject!\n\nGood luck with your final miniproject!\n\n_Note: please let me know if you find any errors in this document!_\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}