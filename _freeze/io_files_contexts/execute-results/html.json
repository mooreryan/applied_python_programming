{
  "hash": "d9295dfd6a57a70762ae6e22761547ff",
  "result": {
    "engine": "jupyter",
    "markdown": "---\nauthor: \"Ryan M. Moore, PhD\"\ndate-modified: last-modified\ndate: \"2025-04-15\"\njupyter: python3\n---\n\n# I/O, Files, & Contexts {#sec-io-files-contexts}\n\nInput and output (I/O) operations are how your programs interact with the outside world. Whether you are taking command line arguments or reading files, you will need to get data into and out of your programs. In this chapter, we will cover the basic concepts (I/O) operations, file handling, and context managers with a focus on bioinformatics applications.\n\n## Install & Import Needed Libraries\n\nFor this module, you well need to ensure that you have `biopython`, `pandas`, and `seaborn` installed.\n\nThen, you can run the imports:\n\n::: {#c399c782 .cell execution_count=1}\n``` {.python .cell-code}\nimport csv\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom Bio import SeqIO\nfrom Bio import SeqUtils\n```\n:::\n\n\n## File Handling Basics\n\nLet's start with some file handling basics: reading, writing, and appending to files.\n\n### Reading from Files\n\nReading files is a common method for importing data into programs, allowing access to pre-existing information such as sequencing reads, experimental data, configuration settings, or user information. Python provides various techniques to control data reading, whether all at once, line by line, or in chunks. Reading a file is non-destructive to the source, as it only creates a memory copy without affecting the original file.\n\nFor the next couple of code blocks, we will be using this file:\n\n::: {#dcadb5a6 .cell execution_count=2}\n``` {.python .cell-code}\nexample_text_file = \"./_data/sample.txt\"\n```\n:::\n\n\n#### Line-by-Line\n\nFirst, let's see how to read a file line-by-line. The `with` statement creates a context manager that automatically closes the file when the block ends. We will talk more about context managers later in the tutorial, but for now, know that this is generally the recommended way to handle files in Python as it ensures proper resource cleanup.\n\n::: {#70207831 .cell execution_count=3}\n``` {.python .cell-code}\n# Open a file `example_text_file` in read mode\nwith open(example_text_file) as file:\n    # Iterate through each line in the file\n    # - enumerate() returns both the index (`i`) and the value (`line`)\n    #   for each iteration\n    # - `i` will start at 0 for the first line, 1 for the second line, etc.\n    for i, line in enumerate(file):\n        # strip() removes whitespace characters (like newlines) from both\n        # ends of the string\n        print(i, line.strip(), sep=\" => \")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0 => Hello, world!\n1 => This text will be added at the end\n```\n:::\n:::\n\n\n#### All at Once\n\nRather than read the data line-by-line, we can read all the data of a file with one function call using the [read()](https://docs.python.org/3/library/io.html#io.TextIOBase.read) method.\n\nRead an entire file at once:\n\n::: {#7ab3026c .cell execution_count=4}\n``` {.python .cell-code}\n# Open a file `example_text_file` in read mode\nwith open(example_text_file) as file:\n    # Read the entire contents of the file and store it in the variable\n    # `content`\n    content = file.read()\n    print(content)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello, world!\nThis text will be added at the end\n```\n:::\n:::\n\n\n#### Reading Chunks\n\nThe `read()` method can also be used to read chunks of a given size:\n\n::: {#b057b2ff .cell execution_count=5}\n``` {.python .cell-code}\nwith open(example_text_file, \"r\") as file:\n    # Reads first 5 characters\n    hello = file.read(5)\n    print(hello)\n\n    # Then read the next 2 characters\n    comma_space = file.read(2)\n    # Use the f-string so you can see the space character\n    print(f\"'{comma_space}'\")\n\n    # And finally the next 6\n    world = file.read(6)\n    print(world)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello\n', '\nworld!\n```\n:::\n:::\n\n\n### Writing to Files\n\nWriting operations generate new files or completely replace existing ones. This enables programs to save results, create logs, or generate reports.\n\nWhen writing to an existing file, previous content is erased unless append mode is used. Because of this, you have to be careful with writing operations to prevent unintended data loss. It's easy to accidentally delete files that you didn't intend to, so it's important to be careful!\n\nFor the next few examples, we will be writing to this file:\n\n::: {#bebc327f .cell execution_count=6}\n``` {.python .cell-code}\noutput_file_name = \"./_tmp/output.txt\"\n```\n:::\n\n\nLet's also write a little helper function to print out the contents of a file. This way, we can see the effect of each of the next few code blocks without cluttering them up:\n\n::: {#cad4b61b .cell execution_count=7}\n``` {.python .cell-code}\ndef print_file_contents(file_name):\n    \"\"\"Print the entire contents of the given file to the console.\"\"\"\n    with open(file_name) as file:\n        contents = file.read()\n        print(contents)\n```\n:::\n\n\n#### Writing to a File\n\nTo write to a file, we need to open the file in write mode. This is done by passing `\"w\"` to the `open` function. Then we need to call the `write()` method on the file object and pass it in some data. Note that this will overwrite the existing file, so be careful!\n\n::: {#5dd9cba9 .cell execution_count=8}\n``` {.python .cell-code}\nwith open(output_file_name, \"w\") as file:\n    file.write(\"Hello, this is my first file!\")\n\nprint_file_contents(output_file_name)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello, this is my first file!\n```\n:::\n:::\n\n\nYou can call `write()` multiple times on the same file object to write multiple times to the same file:\n\n::: {#b6ab9d8a .cell execution_count=9}\n``` {.python .cell-code}\nwith open(output_file_name, \"w\") as file:\n    file.write(\"Line 1: Introduction\\n\")\n    file.write(\"Line 2: Main content\\n\")\n    file.write(\"Line 3: Conclusion\")\n\nprint_file_contents(output_file_name)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLine 1: Introduction\nLine 2: Main content\nLine 3: Conclusion\n```\n:::\n:::\n\n\n::: {#tip-09-missing-data .callout-tip title=\"Stop & Think\" collapse=\"false\"}\nIn the last two examples, we wrote to the same file both times. After the second example, the file no longer included the text `Hello, this is my first file!`. Why is that?\n:::\n\n#### Writing Lines with a Loop\n\nIt is pretty common to have some data in a collection, like a list or dictionary, that you want to write to a file. One way to do this is with a for loop:\n\n::: {#3fe93641 .cell execution_count=10}\n``` {.python .cell-code}\n# Initialize a list of strings\nlines = [\"First line\", \"Second line\", \"Third line\"]\n\n# Create a dictionary mapping protein names to their lengths\nprotein_length = {\"Protein_1\": 500, \"Protein_2\": 750}\n\n# Open a file for writing.\n# - The `\"w\"` specifies that we open the file in \"write\" mode.\n# - The `with` statement ensures file is properly closed when we're done.\nwith open(output_file_name, \"w\") as file:\n    # Iterate through each line in our list\n    for line in lines:\n        # Don't forget to add a newline.\n        # file.write will not add one for you!\n        file.write(line + \"\\n\")\n\n    # Iterate through each key-value pair in the dictionary\n    for protein, length in protein_length.items():\n        # Format a string with protein name and length, including a newline\n        line = f\"{protein} => {length}\\n\"\n        # Write the formatted string to the file\n        file.write(line)\n\n# Display the contents of the file we just created\nprint_file_contents(output_file_name)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFirst line\nSecond line\nThird line\nProtein_1 => 500\nProtein_2 => 750\n\n```\n:::\n:::\n\n\n### Appending to Files\n\nAppending to a file is similar to writing, except that it preserves existing content while adding new information to the end of a file, rather than overwriting the existing data present in the file. This can be useful for logging, data collection over time, or building cumulative reports. Anything were you need to persist some data, and then go back and add more stuff over time. In a way, append operations can be safer than regular write operations because they won't overwrite the file to which you're appending.\n\nHere's how to do it. It's very similar to the writing examples, except that you pass `\"a\"` to the `open()` function rather than `\"w\"`. This gives you a file object in \"append mode\" rather than one in \"write mode\".\n\n::: {#efbf75ab .cell execution_count=11}\n``` {.python .cell-code}\nwith open(output_file_name, \"a\") as file:\n    file.write(\"New line added\\n\")\n\nprint_file_contents(output_file_name)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFirst line\nSecond line\nThird line\nProtein_1 => 500\nProtein_2 => 750\nNew line added\n\n```\n:::\n:::\n\n\nSee how the previous lines we wrote are still in the file output? That's because we're in _append_ mode!\n\nJust like with write mode, you can also append multiple times by looping through some lines:\n\n::: {#12f3b19a .cell execution_count=12}\n``` {.python .cell-code}\nnew_data = [\"Entry 4\", \"Entry 5\", \"Entry 6\"]\n\nwith open(output_file_name, \"a\") as file:\n    for item in new_data:\n        file.write(item + \"\\n\")\n\nprint_file_contents(output_file_name)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFirst line\nSecond line\nThird line\nProtein_1 => 500\nProtein_2 => 750\nNew line added\nEntry 4\nEntry 5\nEntry 6\n\n```\n:::\n:::\n\n\n## File Operation Details\n\nNow that you have seen the basics of reading, writing, and appending, let's go over a few details about file operations.\n\n### Opening and Closing Files\n\nWhen working with files in Python, you'll typically use the [`open()`](https://docs.python.org/3/library/functions.html#open) function with the syntax `file = open(filename, mode)`. The filename parameter can be either a relative or absolute path to your target file. What you get back is a [file object](https://docs.python.org/3/glossary.html#term-file-object) that serves as your interface to the file's contents. The mode parameter is particularly important as it determines what operations you're allowed to perform, including reading, writing, appending, or some combination of these actions (we'll talk more about modes shortly).\n\nAn important aspect of file handling that is easy to overlook is properly closing files when you're done with them. If you're not using Python's `with` statement (which automatically handles closing), you need to explicitly call `file.close()` when your operations are complete. This step is more important than it might seem at first glance: it releases system resources, ensures all data is properly written to disk, and prevents issues like file corruption and memory leaks. In long-running programs, failing to close files can even lead to running out of file descriptors, which can cause your program to crash. Well-behaved Python programs should ensure that file objects are closed when you are finished with them!\n\n### File Modes\n\nThe main file modes you will probably be using are read, write, append, and binary. You can even mix some of the modes when required!\n\n_Note: There are some more modes, like update (`\"+\"`), that we won't go over here. Check them out in the docs if you're interested!_\n\n#### Read: `\"r\"`\n\nThe most common way to open a file in Python is in read mode, which is represented by the letter \"r\". It is the default mode if you don't specify a mode. When you open a file in read mode, Python lets you read the content but doesn't allow you to modify it. The reading automatically starts at the beginning of the file.\n\nOne thing to watch out for though: if you try to open a file that doesn't exist in read mode, Python will raise a `FileNotFoundError` -- you can't read something that isn't there! It's generally a good idea to handle this potential error in your code, especially when working with user-specified file paths.\n\nCheck it out:\n\n::: {#852c2c99 .cell execution_count=13}\n``` {.python .cell-code}\nwith open(example_text_file, \"r\") as file:\n    content = file.read()\n    print(content)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello, world!\nThis text will be added at the end\n```\n:::\n:::\n\n\nSince read-mode is the default, we don't have to pass in the `\"r\"`:\n\n::: {#a6543bde .cell execution_count=14}\n``` {.python .cell-code}\nwith open(example_text_file) as file:\n    content = file.read()\n    print(content)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello, world!\nThis text will be added at the end\n```\n:::\n:::\n\n\nHere's an example of catching the file not found error:\n\n::: {#94809c14 .cell execution_count=15}\n``` {.python .cell-code}\ntry:\n    with open(\"imaginary_file.txt\") as file:\n        content = file.read()\n        print(content)\nexcept FileNotFoundError as error:\n    print(f\"{error=}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nerror=FileNotFoundError(2, 'No such file or directory')\n```\n:::\n:::\n\n\n#### Write: `\"w\"`\n\nYou use write mode (`\"w\"`) when you need to create a file from scratch, or overwrite the contents of an existing file. Write mode gives you a \"fresh start\" on the given file each time it is opened.\n\nYou should be careful when opening a file in write mode. It doesn't ask for confirmation before erasing existing content, so you'll want to be absolutely sure you're passing the correct file name before running your code!\n\n::: {#7c40d4a6 .cell execution_count=16}\n``` {.python .cell-code}\n# Writing to a file (creates new or overwrites existing)\nwith open(example_text_file, \"w\") as file:\n    file.write(\"Hello, world!\")\n\nprint_file_contents(example_text_file)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello, world!\n```\n:::\n:::\n\n\n#### Append: `\"a\"`\n\nUnlike write mode, append opens a file for writing without erasing what's already there. This lets you add data to existing files. If you open a file that doesn't exist yet in append mode, a new file will be created automatically.\n\n::: {#c9a8d953 .cell execution_count=17}\n``` {.python .cell-code}\n# Appending to a file\nwith open(example_text_file, \"a\") as file:\n    file.write(\"\\nThis text will be added at the end\")\n\nprint_file_contents(example_text_file)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello, world!\nThis text will be added at the end\n```\n:::\n:::\n\n\nSee how the output includes both `Hello, world!` and `This text will be added at the end`? That's what append does!\n\n#### Binary: `\"b\"`\n\nThe \"b\" mode specifies binary operations. Adding it to your file mode (like \"rb\" for read-binary or \"wb\" for write-binary) tells Python to handle data as raw bytes rather than text. This is handy when you're dealing with non-text files such as images, audio files, or custom binary formats.\n\nIn binary mode, no encoding or decoding processes occur: what you write is exactly what gets stored. Additionally, Python won't perform any line ending translations that normally happen in text mode, ensuring your data is stored in the file exactly as written.\n\nYou can use binary mode to read the bytes from a PNG image:\n\n::: {#25958ca6 .cell execution_count=18}\n``` {.python .cell-code}\nwith open(\"./_data/star.png\", \"rb\") as file:\n    image_data = file.read()\n    print(image_data[:11])\n    # Process the PNG data...\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nb'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00'\n```\n:::\n:::\n\n\nUsing, `\"wb\"` let's you write raw bytes to an output file:\n\n::: {#8f0d2a26 .cell execution_count=19}\n``` {.python .cell-code}\n# Some mysterious bytes data\ndata = b\"\\x48\\x65\\x6c\\x6c\\x6f\\x2c\\x20\\x57\\x6f\\x72\\x6c\\x64\\x21\"\n\nwith open(\"./_tmp/binary_output\", \"wb\") as file:\n    # Write raw bytes to the file\n    file.write(data)\n\nprint_file_contents(\"./_tmp/binary_output\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello, World!\n```\n:::\n:::\n\n\nBinary mode might be a bit mysterious, so let me copy in a paragraph straight from the Python docs for the [open()](https://docs.python.org/3/library/functions.html#open) function that might help to make it more clear:\n\n> As mentioned in the [Overview](https://docs.python.org/3/library/io.html#io-overview), Python distinguishes between binary and text I/O. Files opened in binary mode (including 'b' in the mode argument) return contents as [bytes](https://docs.python.org/3/library/stdtypes.html#bytes) objects without any decoding. In text mode (the default, or when 't' is included in the mode argument), the contents of the file are returned as [str](https://docs.python.org/3/library/stdtypes.html#str), the bytes having been first decoded using a platform-dependent encoding or using the specified encoding if given.\n\n#### Text: `\"t\"`\n\nText mode is sort of the opposite of binary mode in a way. It handles data as strings with the default encoding/decoding scheme, automatically manages line ending differences between operating systems, and is most appropriate for human-readable text files like FASTA files, CSV, and other plain text files.\n\n_Note: You generally don't have to specify `\"t\"` manually as it is the default mode (as opposed to binary mode)._\n\n::: {#1bb5274e .cell execution_count=20}\n``` {.python .cell-code}\n# Text mode is the default, so the \"t\" is optional here.\n# Also...read mode is the default, so technically both \"r\" and \"t\"\n# are optional here!\nwith open(example_text_file, \"rt\") as file:\n    text = file.read()\n    print(text)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello, world!\nThis text will be added at the end\n```\n:::\n:::\n\n\n### File Objects\n\nPython's file handling system centers around file objects -- interfaces that provide methods like `read()` and `write()` -- to interact with underlying resources. Though named \"file\" objects, these abstractions extend beyond disk files.\n\n#### What Are File Objects?\n\n[File objects](https://docs.python.org/3/glossary.html#term-file-object) provide a file-like API (reading, writing) to some underlying resource (like an on-disk file, an in-memory buffer, standard input/output).\n\nThere are three categories of file objects: raw [binary files](https://docs.python.org/3/glossary.html#term-binary-file), buffered binary files and [text files](https://docs.python.org/3/glossary.html#term-text-file).\n\nAll these interfaces are defined in the [`io`](https://docs.python.org/3/library/io.html#module-io) module, though you typically don't need to interact with this module directly. Rather, you generally create file objects using the [open()](https://docs.python.org/3/library/functions.html#open) function.\n\n#### Creating File Objects\n\nThe standard way to create a file object is through the built-in [open()](https://docs.python.org/3/library/functions.html#open) function, as in the examples above. This function determines which type of file object to create based on the mode and other parameters you provide.\n\nLet's create a file object with `open()` and then access some info about it:\n\n::: {#4e9afd50 .cell execution_count=21}\n``` {.python .cell-code}\nwith open(example_text_file) as file:\n    print(\"Inside the 'with' block\")\n    print(f\"- {file.name=}\")\n    print(f\"- {file.mode=}\")\n    print(f\"- {file.closed=}\")\n\nprint(\"\\nOutside the 'with' block\")\nprint(f\"- {file.closed=}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nInside the 'with' block\n- file.name='./_data/sample.txt'\n- file.mode='r'\n- file.closed=False\n\nOutside the 'with' block\n- file.closed=True\n```\n:::\n:::\n\n\n- `file.name`: Returns the name of the file\n- `file.mode`: Shows the mode in which the file was opened\n- `file.closed`: Boolean indicating if the file is closed\n\nLet's see an example where we track our location in the file as we loop through its lines.\n\n::: {#ebec0bf2 .cell execution_count=22}\n``` {.python .cell-code}\ndata_file = \"./_tmp/small_file.txt\"\n\n# First, write some data to work with\nwith open(data_file, \"wb\") as file:\n    file.write(b\"a\\n\")\n    file.write(b\"bc\\n\")\n    file.write(b\"def\\n\")\n    file.write(b\"ghij\\n\")\n    file.write(b\"klmno\\n\")\n\n\nprint_file_contents(data_file)\n\nwith open(data_file, \"rb\") as file:\n    print(f\"Before reading line 1:\")\n    print(f\"- {file.tell()=}\")\n\n    for i, line in enumerate(file):\n        print(f\"After reading line {i + 1}:\")\n        print(f\"- {file.tell()=}\")\n        print(f\"- {len(line)=}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\na\nbc\ndef\nghij\nklmno\n\nBefore reading line 1:\n- file.tell()=0\nAfter reading line 1:\n- file.tell()=2\n- len(line)=2\nAfter reading line 2:\n- file.tell()=5\n- len(line)=3\nAfter reading line 3:\n- file.tell()=9\n- len(line)=4\nAfter reading line 4:\n- file.tell()=14\n- len(line)=5\nAfter reading line 5:\n- file.tell()=20\n- len(line)=6\n```\n:::\n:::\n\n\nThis example used the [tell()](https://docs.python.org/3/tutorial/inputoutput.html#methods-of-file-objects) method:\n\n> f.tell() returns an integer giving the file object’s current position in the file represented as number of bytes from the beginning of the file when in binary mode and an opaque number when in text mode.\n\n_Note: it says \"opaque number\" in text mode because the encoding/decoding might make it so that the returned number doesn't always line up with the number of bytes._\n\nFinally, let's do something a bit tricky...\n\n::: {#30985cae .cell execution_count=23}\n``` {.python .cell-code}\nwith open(data_file, \"rb\") as file:\n    print(f\"{file.read(2)=}\")\n    print(f\"{file.read(3)=}\")\n    print(f\"{file.read(4)=}\")\n\n    print(\"going back to the beginning!\")\n    file.seek(0)\n\n    print(\"starting to loop through the lines!\")\n    for line in file:\n        print(line)\n\n        if len(line) % 2 == 0:\n            file.seek(-len(line), 1)\n            extra_read = file.read(len(line))\n            print(f\"{extra_read=}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfile.read(2)=b'a\\n'\nfile.read(3)=b'bc\\n'\nfile.read(4)=b'def\\n'\ngoing back to the beginning!\nstarting to loop through the lines!\nb'a\\n'\nextra_read=b'a\\n'\nb'bc\\n'\nb'def\\n'\nextra_read=b'def\\n'\nb'ghij\\n'\nb'klmno\\n'\nextra_read=b'klmno\\n'\n```\n:::\n:::\n\n\nTo summarize the last two examples:\n\n- Position tracking with `tell()` and `seek()`\n  - `tell()`: Returns the current position of the file pointer\n  - `seek(offset, whence)`: Moves the pointer to a specified position relative to the location specified by [`whence`](https://dictionary.cambridge.org/us/dictionary/english/whence)\n  - `whence` can be 0 (start), 1 (current position), or 2 (end). (Not all options for whence are available in all modes! See the [docs](https://docs.python.org/3/tutorial/inputoutput.html#methods-of-file-objects).)\n\nYou might not always need to manually move around files like this, but it is an option there for you when you need it!\n\n#### More File Object Methods\n\nThe [io](https://docs.python.org/3/library/io.html) module provides some other methods that you can use with file objects like `readlines()`, `writelines()`, and others. Check out the docs for the module to learn more!\n\n## Working with Context Managers\n\nIn Python, the `with` statement is generally the preferred way to handle files, as it creates a context manager that automatically takes care of closing them. The syntax is straightforward: write `with open(filename, mode) as file:` and work with your file inside the indented block.\n\nWhat makes this approach so nice is that it guarantees proper cleanup even if exceptions occur during your file operations. This saves you from having to write explicit `try/except` blocks to ensure files get closed properly. The `with` statement also improves code readability by clearly defining the scope of your file operations. Additionally, if you need to work with multiple files at once, you can nest `with` statements, or put multiple `with` statements in a single line.\n\nHere's a small example demonstrating the use of `with`:\n\n::: {#2680dc87 .cell execution_count=24}\n``` {.python .cell-code}\nwith open(example_text_file, \"r\") as file:\n    content = file.read()\n    print(content)\n\n# The file will be closed once you get here,\n# so this will run the `except` clause.\ntry:\n    file.read()\nexcept ValueError as error:\n    print(f\"{error=}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello, world!\nThis text will be added at the end\nerror=ValueError('I/O operation on closed file.')\n```\n:::\n:::\n\n\nWe have been using the `with` statement throughout the tutorial, but let's take a bit of a deeper look at what is going on _with_ it (ha).\n\nTake a look at this code, where we open a file for writing, then do a write, then explicitly close the file object:\n\n::: {#66deeaf8 .cell execution_count=25}\n``` {.python .cell-code}\nfile = open(\"./_tmp/some_file.txt\", \"w\")\n\nfile.write(\"Some data\\n\")\n\n# You should remember to close the file here after you're done with it!\nfile.close()\n```\n:::\n\n\nCompare it to this code, where you don't have to manage the lifecycle of the file object:\n\n::: {#aee78b42 .cell execution_count=26}\n``` {.python .cell-code}\nwith open(\"./_tmp/some_file.txt\", \"w\") as file:\n    file.write(\"Some data\\n\")\n\n# No need to explicitly close the file!\n# `with` takes care of that for you\n```\n:::\n\n\nIn the second example, you don't have to worry about forgetting to close the file yourself!\n\nThere is actually a lot more to context managers than what we have covered here. However, you will probably be happy to know that we aren't going to go into all that in this course!\n\n## Error Handling in File Operations\n\nThere are a few common errors that file operations can raise. Let's take a look at some of them now.\n\n### `FileNotFoundError`\n\nA `FileNotFoundError` when opening nonexistent files. This occurs when you try to open a file that doesn't exist:\n\n::: {#ee96ccf6 .cell execution_count=27}\n``` {.python .cell-code}\ntry:\n    with open(\"nonexistent_file.txt\", \"r\") as file:\n        content = file.read()\nexcept FileNotFoundError as error:\n    print(f\"{error=}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nerror=FileNotFoundError(2, 'No such file or directory')\n```\n:::\n:::\n\n\n### `PermissionError`\n\nA `PermissionError` when lacking file access rights. This happens when your program doesn't have the necessary permissions to access a file:\n\n::: {#f31a2669 .cell execution_count=28}\n``` {.python .cell-code}\ntry:\n    with open(\"./_tmp/secret_file.txt\") as file:\n        content = file.read()\nexcept PermissionError as error:\n    print(f\"{error=}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nerror=PermissionError(13, 'Permission denied')\n```\n:::\n:::\n\n\n### `IsADirectoryError` and `NotADirectoryError`\n\n`IsADirectoryError` and `NotADirectoryError` occur when you confuse files and directories.\n\nTrying to open a directory as a file:\n\n::: {#53e68ed2 .cell execution_count=29}\n``` {.python .cell-code}\ntry:\n    with open(\"./_tmp\") as file:\n        content = file.read()\nexcept IsADirectoryError as error:\n    print(f\"{error=}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nerror=IsADirectoryError(21, 'Is a directory')\n```\n:::\n:::\n\n\nIn this case, we are passing a directory where we expect to get a file, so it raises an error.\n\nTrying to use a file as a directory:\n\n::: {#554fcf9a .cell execution_count=30}\n``` {.python .cell-code}\ntry:\n    os.listdir(example_text_file)\nexcept NotADirectoryError as error:\n    print(f\"{error=}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nerror=NotADirectoryError(20, 'Not a directory')\n```\n:::\n:::\n\n\nHere we are using the [listdir()](https://docs.python.org/3/library/os.html#os.listdir) function, which attempts to return a list containing the names of the entries in the given directory. However, it won't work because we are passing it a file!\n\n### Catching OSError\n\nSometimes, you might want to catch any type of OS error and handle them all in the same way. You can use `OSError` for this. Let's rewrite the above examples to all catch `OSError` instead of the more specific error messages.\n\n::: {#9d19ad87 .cell execution_count=31}\n``` {.python .cell-code}\ntry:\n    with open(\"nonexistent_file.txt\", \"r\") as file:\n        content = file.read()\nexcept OSError as error:\n    print(f\"{error=}\")\n\ntry:\n    with open(\"./_tmp/secret_file.txt\") as file:\n        content = file.read()\nexcept OSError as error:\n    print(f\"{error=}\")\n\ntry:\n    with open(\"./_tmp\") as file:\n        content = file.read()\nexcept OSError as error:\n    print(f\"{error=}\")\n\ntry:\n    os.listdir(example_text_file)\nexcept OSError as error:\n    print(f\"{error=}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nerror=FileNotFoundError(2, 'No such file or directory')\nerror=PermissionError(13, 'Permission denied')\nerror=IsADirectoryError(21, 'Is a directory')\nerror=NotADirectoryError(20, 'Not a directory')\n```\n:::\n:::\n\n\n### Catching Multiple Specific Errors\n\nSometimes you may want to catch multiple different kinds of errors for a single operation. This way, you can give your users nice error messages, which can help them fix any problems that may have occurred. It's generally a good idea to give as much detail as you think your users will need to help them understand what went wrong.\n\n::: {#8dc9b860 .cell execution_count=32}\n``` {.python .cell-code}\ntry:\n    with open(\"not_a_real_file.txt\") as file:\n        content = file.read()\nexcept FileNotFoundError:\n    print(\"File not found. Please check the file path.\")\nexcept PermissionError:\n    print(\"Permission denied. Check your access rights.\")\nexcept Exception as e:\n    print(f\"An unexpected error occurred: {e}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFile not found. Please check the file path.\n```\n:::\n:::\n\n\n::: {#tip-09-improving-error-messages .callout-tip title=\"Stop & Think\" collapse=\"false\"}\nHow could you improve the error messages in the previous code block?\n:::\n\n## Common Bioinformatics File Formats\n\nThe bioinformatics field relies on numerous specialized file formats to store and share biological data. Familiarity with these formats is important for any bioinformatics programmer. Let's explore some of the common file formats you'll encounter.\n\nFor this section, we will be using [biopython](https://biopython.org/). While it is always a fun activity to write your own parsers, it's generally a good idea to stick with established solutions when they are available.\n\n### FASTA\n\n[FASTA](https://en.wikipedia.org/wiki/FASTA_format) is probably the most common sequence format in bioinformatics. It uses a simple structure with header lines (starting with '>' character) followed by the biological sequence data (DNA, RNA, or protein). It is widely used for storing and exchanging sequence data. For example, here are two sequences from [UniProt](https://www.uniprot.org/) in FASTA format.\n\n```\n>sp|P00452|RIR1_ECOLI Ribonucleoside-diphosphate reductase 1 subunit alpha OS=Escherichia coli (strain K12) OX=83333 GN=nrdA PE=1 SV=2\nMNQNLLVTKRDGSTERINLDKIHRVLDWAAEGLHNVSISQVELRSHIQFYDGIKTSDIHE\nTIIKAAADLISRDAPDYQYLAARLAIFHLRKKAYGQFEPPALYDHVVKMVEMGKYDNHLL\nEDYTEEEFKQMDTFIDHDRDMTFSYAAVKQLEGKYLVQNRVTGEIYESAQFLYILVAACL\nFSNYPRETRLQYVKRFYDAVSTFKISLPTPIMSGVRTPTRQFSSCVLIECGDSLDSINAT\nSSAIVKYVSQRAGIGINAGRIRALGSPIRGGEAFHTGCIPFYKHFQTAVKSCSQGGVRGG\nAATLFYPMWHLEVESLLVLKNNRGVEGNRVRHMDYGVQINKLMYTRLLKGEDITLFSPSD\nVPGLYDAFFADQEEFERLYTKYEKDDSIRKQRVKAVELFSLMMQERASTGRIYIQNVDHC\nNTHSPFDPAIAPVRQSNLCLEIALPTKPLNDVNDENGEIALCTLSAFNLGAINNLDELEE\nLAILAVRALDALLDYQDYPIPAAKRGAMGRRTLGIGVINFAYYLAKHGKRYSDGSANNLT\nHKTFEAIQYYLLKASNELAKEQGACPWFNETTYAKGILPIDTYKKDLDTIANEPLHYDWE\nALRESIKTHGLRNSTLSALMPSETSSQISNATNGIEPPRGYVSIKASKDGILRQVVPDYE\nHLHDAYELLWEMPGNDGYLQLVGIMQKFIDQSISANTNYDPSRFPSGKVPMQQLLKDLLT\nAYKFGVKTLYYQNTRDGAEDAQDDLVPSIQDDGCESGACKI\n>sp|P37426|RIR1_SALTY Ribonucleoside-diphosphate reductase 1 subunit alpha OS=Salmonella typhimurium (strain LT2 / SGSC1412 / ATCC 700720) OX=99287 GN=nrdA PE=3 SV=1\nMNQSLLVTKRDGRTERINLDKIHRVLDWAAEGLNNVSVSQVELRSHIQFYDGIKTSDIHE\nTIIKAAADLISRDAPDYQYLAARLAIFHLRKKAFGQFEPPALYHHVVKMVELGKYDNHLL\nEDYTEEEFKQMDSFIVHDRDMTFSYAAVKQLEGKYLVQNRVTGEIYESAQFLYILVAACL\nFSNYPRETRLDYVKRFYDAVSTFKISLPTPIMSGVRTPTRQFSSCVLIECGDSLDSINAT\nSSAIVKYVSQRAGIGINAGRIRALGSPIRGGEAFHTGCIPFYKHFQTAVKSCSQGGVRGG\nAATLFYPMWHLEVESLLVLKNNRGVEGNRVRHMDYGVQINKLMYTRLLKGGDITLFSPSD\nVPGLYDAFFADQDEFERLYVKYEHDDSIRKQRVKAVELFSLMMQERASTGRIYIQNVDHC\nNTHSPFDPVVAPVRQSNLCLEIALPTKPLNDVNDENGEIALCTLSAFNLGAIKTLDELEE\nLAILAVRALDALLDYQDYPIPAAKRGAMGRRTLGIGVINFAYWLAKNGKRYSDGSANNLT\nHKTFEAIQYYLLKASNELAKEQGACPWFNETTYAKGILPIDTYKKDLDAIVNEPLHYDWE\nQLRESIKTHGLRNSTLSALMPSETSSQISNATNGIEPPRGYVSIKASKDGILRQVVPDYE\nHLKDAYELLWEMPNNDGYLQLVGIMQKFIDQSISANTNYDPSRFPSGKVPMQQLLKDLLT\nAYKFGVKTLYYQNTRDGAEDAQDDLAPSIQDDGCESGACKI\n```\n\nNotice how the header line (the one starting with `>`) has a regular format. That will _not_ always be the case. The format of the header line is highly dependent on the vendor or the software that generated it. This is the same sequence as the first one, except that it was downloaded from [NCBI](https://www.ncbi.nlm.nih.gov/protein/NP_416737.1?report=fasta) rather than UniProt.\n\n```\n>NP_416737.1 ribonucleoside-diphosphate reductase 1 subunit alpha [Escherichia coli str. K-12 substr. MG1655]\nMNQNLLVTKRDGSTERINLDKIHRVLDWAAEGLHNVSISQVELRSHIQFYDGIKTSDIHETIIKAAADLI\nSRDAPDYQYLAARLAIFHLRKKAYGQFEPPALYDHVVKMVEMGKYDNHLLEDYTEEEFKQMDTFIDHDRD\nMTFSYAAVKQLEGKYLVQNRVTGEIYESAQFLYILVAACLFSNYPRETRLQYVKRFYDAVSTFKISLPTP\nIMSGVRTPTRQFSSCVLIECGDSLDSINATSSAIVKYVSQRAGIGINAGRIRALGSPIRGGEAFHTGCIP\nFYKHFQTAVKSCSQGGVRGGAATLFYPMWHLEVESLLVLKNNRGVEGNRVRHMDYGVQINKLMYTRLLKG\nEDITLFSPSDVPGLYDAFFADQEEFERLYTKYEKDDSIRKQRVKAVELFSLMMQERASTGRIYIQNVDHC\nNTHSPFDPAIAPVRQSNLCLEIALPTKPLNDVNDENGEIALCTLSAFNLGAINNLDELEELAILAVRALD\nALLDYQDYPIPAAKRGAMGRRTLGIGVINFAYYLAKHGKRYSDGSANNLTHKTFEAIQYYLLKASNELAK\nEQGACPWFNETTYAKGILPIDTYKKDLDTIANEPLHYDWEALRESIKTHGLRNSTLSALMPSETSSQISN\nATNGIEPPRGYVSIKASKDGILRQVVPDYEHLHDAYELLWEMPGNDGYLQLVGIMQKFIDQSISANTNYD\nPSRFPSGKVPMQQLLKDLLTAYKFGVKTLYYQNTRDGAEDAQDDLVPSIQDDGCESGACKI\n```\n\nNot only is the header different, but the length of each of the lines in the sequence is different as well. You will even sometimes see the sequence all one line as well. A good parser will be able to handle these minor variations in the format.\n\n#### Parsing FASTA Files\n\nThe simplest way to parse a FASTA file using [biopython](https://biopython.org/) is by using the [SeqIO.parse()](https://biopython.org/docs/1.75/api/Bio.SeqIO.html#Bio.SeqIO.parse) function:\n\n::: {#e772d4f6 .cell execution_count=33}\n``` {.python .cell-code}\n# Loop over all records in the given FASTA file\nfor record in SeqIO.parse(\"./_data/example.fasta\", \"fasta\"):\n    # Print out some info about the returned SeqRecord instance\n    print()\n    print(f\"{type(record)=}\")\n    print(f\"{record.id=}\")\n    print(f\"{record.seq=}\")\n    print(f\"{len(record.seq)=}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\ntype(record)=<class 'Bio.SeqRecord.SeqRecord'>\nrecord.id='sp|P00452|RIR1_ECOLI'\nrecord.seq=Seq('MNQNLLVTKRDGSTERINLDKIHRVLDWAAEGLHNVSISQVELRSHIQFYDGIK...CKI')\nlen(record.seq)=761\n\ntype(record)=<class 'Bio.SeqRecord.SeqRecord'>\nrecord.id='sp|P37426|RIR1_SALTY'\nrecord.seq=Seq('MNQSLLVTKRDGRTERINLDKIHRVLDWAAEGLNNVSVSQVELRSHIQFYDGIK...CKI')\nlen(record.seq)=761\n```\n:::\n:::\n\n\nThis lets you iterate over all the records in the FASTA file by giving you [SeqRecord](https://biopython.org/wiki/SeqRecord) instances for each record in the FASTA file. The `SeqRecord` class has many useful methods, so be sure to check out the docs when using it in your own research!\n\n### FASTQ\n\n[FASTQ](https://en.wikipedia.org/wiki/FASTQ_format) extends the FASTA format by adding quality scores for each base in the sequence, making it the standard format for high-throughput sequencing data. Generally, each entry consists of four lines: a header (starting with '@'), the sequence, a separator line (starting with '+'), and [Phred quality scores](https://en.wikipedia.org/wiki/Phred_quality_score) encoded as ASCII characters. For example:\n\n```\n@HWI-ST741:607:HCJFYBCXX:2:1101:1362:1894 1:N:0:GCCAAT\nGGCTCATACAAATATTACTCCTTAAACGTGAGTATCGAATACAGCCATCAAAGATCTGAGATCCTTCGAA\n+\nIIIHHHIIIIHEGHIHHIIEHI@@@ECHFH@;D?EHHI@A--AFC-GHII?HHCHEHHH@-4+@EHE---\n@HWI-ST741:607:HCJFYBCXX:2:1101:1489:1973 1:N:0:GCCAAT\nGGAGCTTCATAAAAAATTCGGCTGTGACATTGTAATTCACATGTGTCATCATAGACAAGACCTTTCGTCT\n+\nFC///:/.D@ECC.FHF@.---7G?-AH-6@@-6BHEH?H?@G--55A:@4-6-6-55AHE?G-8-6@-6\n```\n\n_Note that there is the multi-line FASTQ format, but it is not as common._\n\n#### Parsing FASTQ Files\n\nThis code is almost exactly the same as for parsing the FASTA file. The only difference is that we need to specify `\"fastq\"` for the `SeqIO.parse()` function.\n\n::: {#4441ff37 .cell execution_count=34}\n``` {.python .cell-code}\n# Loop over all records in the given FASTA file\nfor record in SeqIO.parse(\"./_data/example.fastq\", \"fastq\"):\n    # Print out some info about the returned SeqRecord instance\n    print()\n    print(f\"{type(record)=}\")\n    print(f\"{record.id=}\")\n    print(f\"{record.seq=}\")\n    print(f\"{len(record.seq)=}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\ntype(record)=<class 'Bio.SeqRecord.SeqRecord'>\nrecord.id='HWI-ST741:607:HCJFYBCXX:2:1101:1362:1894'\nrecord.seq=Seq('GGCTCATACAAATATTACTCCTTAAACGTGAGTATCGAATACAGCCATCAAAGA...GAA')\nlen(record.seq)=70\n\ntype(record)=<class 'Bio.SeqRecord.SeqRecord'>\nrecord.id='HWI-ST741:607:HCJFYBCXX:2:1101:1489:1973'\nrecord.seq=Seq('GGAGCTTCATAAAAAATTCGGCTGTGACATTGTAATTCACATGTGTCATCATAG...TCT')\nlen(record.seq)=70\n```\n:::\n:::\n\n\nOne thing that's really nice about biopython is that you can use the same interface for multiple different types of files!\n\n::: {#tip-09-parse-fasta-fastq .callout-tip title=\"Stop & Think\" collapse=\"false\"}\nWhat do you think would happen if you tried to parse a FASTA file, but passed `\"fastq\"` as the second argument to `SeqIO.parse()`?\n:::\n\n### Tabular Data\n\nWhile not a \"bioinformatics\" format _per se_, CSV and TSV are so common and important that I wanted to at least show an example of how to parse them in Python. Python’s built-in [csv](https://docs.python.org/3/library/csv.html#module-csv) module makes working with tabular data like CSV and TSV files easy and flexible. It simplifies converting between tabular formats and Python data structures, streamlining both data import and export without added complexity. You can customize delimiters and use [DictReader](https://docs.python.org/3/library/csv.html#module-csv:~:text=form%20using%20the-,DictReader,-and%20DictWriter%20classes) and [DictWriter](https://docs.python.org/3/library/csv.html#csv.DictWriter) for more readable, field-based access.\n\nLet's see it in action.\n\n#### Parsing CSV/TSV\n\nSay we have a CSV file called `example.csv` representing a graph that looks like this:\n\n```CSV\nTaxa1,Taxa2,57\nTaxa1,Taxa3,89\nTaxa1,Taxa4,120\nTaxa2,Taxa3,73\n```\n\nLet's see how to parse it:\n\n::: {#ee936a92 .cell execution_count=35}\n``` {.python .cell-code}\nwith open(\"./_data/example.csv\", newline=\"\") as csv_file:\n    for record in csv.DictReader(csv_file, fieldnames=(\"Source\", \"Target\", \"Score\")):\n        print(record)\n        print(record[\"Source\"], record[\"Target\"], sep=\" => \")\n        print()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'Source': 'Taxa1', 'Target': 'Taxa2', 'Score': '57'}\nTaxa1 => Taxa2\n\n{'Source': 'Taxa1', 'Target': 'Taxa3', 'Score': '89'}\nTaxa1 => Taxa3\n\n{'Source': 'Taxa1', 'Target': 'Taxa4', 'Score': '120'}\nTaxa1 => Taxa4\n\n{'Source': 'Taxa2', 'Target': 'Taxa3', 'Score': '73'}\nTaxa2 => Taxa3\n\n```\n:::\n:::\n\n\nThe following code opens and reads a CSV file, then processes and prints each record in a specific format.\n\n::: {#e01e5d1d .cell execution_count=36}\n``` {.python .cell-code}\n# Open the CSV file located at \"./_data/example.csv\" in read mode\n# - The 'newline=\"\"' argument ensures consistent newline handling across\n#   platforms. It activates universal newlines mode, but line endings are\n#   returned to the caller untranslated.\nwith open(\"./_data/example.csv\", newline=\"\") as csv_file:\n    # Use csv.DictReader to iterate through each row of the CSV file\n    # - fieldnames=(\"Source\", \"Target\", \"Score\") specifies column names to use\n    # - If the CSV file already has headers, you would typically omit this\n    #   parameter\n    for record in csv.DictReader(\n        csv_file,\n        fieldnames=(\"Source\", \"Target\", \"Score\"),\n    ):\n        # Print the entire record as a dictionary\n        print(record)\n\n        # Print just the Source and Target values, separated by \" => \"\n        print(record[\"Source\"], record[\"Target\"], sep=\" => \")\n\n        # Print an empty line for better readability between records\n        print()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'Source': 'Taxa1', 'Target': 'Taxa2', 'Score': '57'}\nTaxa1 => Taxa2\n\n{'Source': 'Taxa1', 'Target': 'Taxa3', 'Score': '89'}\nTaxa1 => Taxa3\n\n{'Source': 'Taxa1', 'Target': 'Taxa4', 'Score': '120'}\nTaxa1 => Taxa4\n\n{'Source': 'Taxa2', 'Target': 'Taxa3', 'Score': '73'}\nTaxa2 => Taxa3\n\n```\n:::\n:::\n\n\nIn this case, we specified the field names, since our input file did not have a header row. There are a lot of other [options](https://docs.python.org/3/library/csv.html#csv.reader) that can be specified, but this simple example will take you pretty far!\n\nLet's see one more example, but this time the CSV file has a header row. It's pretty much the same, except that we don't need to specify the `fieldnames`.\n\n::: {#3b2a0069 .cell execution_count=37}\n``` {.python .cell-code}\nwith open(\"./_data/example_with_header.csv\", newline=\"\") as csv_file:\n    for record in csv.DictReader(csv_file):\n        print(record)\n        print(record[\"Source\"], record[\"Target\"], sep=\" => \")\n        print()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'Source': 'Taxa1', 'Target': 'Taxa2', 'Score': '57'}\nTaxa1 => Taxa2\n\n{'Source': 'Taxa1', 'Target': 'Taxa3', 'Score': '89'}\nTaxa1 => Taxa3\n\n{'Source': 'Taxa1', 'Target': 'Taxa4', 'Score': '120'}\nTaxa1 => Taxa4\n\n{'Source': 'Taxa2', 'Target': 'Taxa3', 'Score': '73'}\nTaxa2 => Taxa3\n\n```\n:::\n:::\n\n\n::: {#tip-09-csv-no-header .callout-tip title=\"Stop & Think\" collapse=\"false\"}\nWhat do you think would happen if you did not specify the field names in a CSV file that did not have a header line?\n:::\n\n## Example: Processing FASTQ Files\n\nTo wrap up, let's see a small example that reads in FASTQ files for two samples, and then generates plots of the distribution of quality scores and the GC content across reads in both samples.\n\n::: {#a5e30504 .cell execution_count=38}\n``` {.python .cell-code}\n# Define a list of sample names for processing\nsample_names = [\"Sample_1\", \"Sample_2\"]\n\n# Create a dictionary mapping sample names to their respective FASTQ file\n# paths\nfastq_files = {\n    \"Sample_1\": \"./_data/sample_1.fastq\",\n    \"Sample_2\": \"./_data/sample_2.fastq\",\n}\n\n# Initialize an empty list to store processed data from each sequence record\nrecords = []\n\n# Loop through each sample\nfor sample in sample_names:\n    # Parse each FASTQ file using BioPython's SeqIO module\n    for record in SeqIO.parse(fastq_files[sample], \"fastq\"):\n        # Calculate the mean quality score for the current sequence\n        quality_score = np.mean(record.letter_annotations[\"phred_quality\"])\n\n        # Calculate the GC content as a percentage using BioPython's SeqUtils\n        gc_content = SeqUtils.gc_fraction(record) * 100\n\n        # Add the sample information, quality score, and GC content to our\n        # records list\n        records.append(\n            {\n                \"Sample\": sample,\n                \"Mean Quality Score\": quality_score,\n                \"GC Content (%)\": gc_content,\n            }\n        )\n\n# Convert the collected records into a pandas DataFrame for analysis\nquality_score_data = pd.DataFrame(records)\n\n# Display the DataFrame to show the collected data\ndisplay(quality_score_data)\n\n# Create a kernel density estimate (KDE) plot for the quality scores,\n# separating the samples by color (hue)\nsns.displot(\n    quality_score_data,\n    kind=\"kde\",  # Create a kernel density estimate plot\n    x=\"Mean Quality Score\",  # Use quality scores for x-axis\n    hue=\"Sample\",  # Color by sample\n    fill=True,  # Fill the area under the curves\n    height=2,  # Set plot height\n    aspect=2,  # Set plot width:height ratio\n)\n\nsns.displot(\n    quality_score_data,\n    kind=\"kde\",  # Create a kernel density estimate plot\n    x=\"GC Content (%)\",  # Use GC content for x-axis\n    hue=\"Sample\",  # Color by sample\n    fill=True,  # Fill the area under the curves\n    height=2,  # Set plot height\n    aspect=2,  # Set plot width:height ratio\n)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sample</th>\n      <th>Mean Quality Score</th>\n      <th>GC Content (%)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sample_1</td>\n      <td>23.757143</td>\n      <td>58.571429</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sample_1</td>\n      <td>24.114286</td>\n      <td>62.857143</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sample_1</td>\n      <td>22.328571</td>\n      <td>54.285714</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sample_1</td>\n      <td>23.357143</td>\n      <td>65.714286</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sample_1</td>\n      <td>22.157143</td>\n      <td>71.428571</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>Sample_2</td>\n      <td>33.885714</td>\n      <td>55.714286</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>Sample_2</td>\n      <td>32.700000</td>\n      <td>54.285714</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>Sample_2</td>\n      <td>31.071429</td>\n      <td>45.714286</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>Sample_2</td>\n      <td>29.771429</td>\n      <td>42.857143</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>Sample_2</td>\n      <td>33.471429</td>\n      <td>52.857143</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 3 columns</p>\n</div>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](io_files_contexts_files/figure-html/cell-39-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](io_files_contexts_files/figure-html/cell-39-output-3.png){}\n:::\n:::\n\n\n## Wrap-Up\n\nIn this chapter, we've explored the fundamentals of file handling in Python, with a particular focus on bioinformatics applications. We covered how to read from, write to, and append to files using different modes like text and binary. We also learned about context managers with the `with` statement, which ensure proper resource cleanup, and explored common file-related error handling techniques.\n\nBeyond the basics, we examined how to work with common bioinformatics file formats like FASTA and FASTQ using BioPython, and saw how to process tabular data with Python's csv module. The practical example of processing FASTQ files demonstrated how these concepts might come together in real bioinformatics workflows.\n\nThese file handling skills are essential for any bioinformatics programmer, as many analyses involve importing, processing, and exporting data from various file formats. As you continue your programming journey, these techniques will serve as key components in your applications.\n\n## Suggested Reading\n\n- Python's [Input & Output](https://docs.python.org/3/tutorial/inputoutput.html) docs\n- Python's [io](https://docs.python.org/3/library/io.html) module docs\n- [Context Managers and Python's with Statement](https://realpython.com/python-with-statement/)\n\n## Practice Problems\n\nGive these problems a try if you’d like some extra practice! They’re organized into groups based on similar levels of difficulty.\n\nYou can find the solutions here: @sec-io-files-contexts-practice-problem-solutions\n\n### Group 1\n\n1. Open a file called `data.txt` for reading, print its type, then close it.\n2. Write \"Hello, World!\" into a file named `test.txt`.\n3. Read and print all text from a file named `sample.txt`.\n4. Read a file line by line and print each line without the trailing newline character(s).\n5. Append the text \"New Entry\" to `log.txt`.\n6. Print the file's name and mode after opening it.\n7. Write three lines to `multi.txt`: \"One\", \"Two\", \"Three\", each on its own line.\n8. Use a for-loop to write the numbers 1-5 to a file (one per line).\n9. Print `\"File is closed\"` if file is closed after exiting a `with`-block.\n10. Use `readline()` to read and print just the first line of `sample.txt`.\n11. Create a function that prints the contents of a file it is given.\n12. Use a `for` loop to write a list of fruits into a file, one fruit per line.\n13. Read and print the first eight characters of `sample.txt`.\n14. Demonstrate that opening an existing file in write mode (`\"w\"`) mode erases its contents.\n15. Use a try-except block to print a message if `not_a_file.txt` does not exist.\n16. Print file position (using `.tell()`) before and after reading 4 bytes.\n17. Write binary bytes `b'ABC'` to a file called `bytes.bin`.\n18. Read the binary file you just created (`bytes.bin`) and print the first five bytes.\n19. Use `\"rt\"` mode to read text and `\"wb\"` mode to write bytes.\n20. Print the error message if a file open operation raises an `OSError`.\n21. Print the first line from a file, then use `.seek(0)` to go back to the beginning of the file and re-print the first line.\n22. Use `with` statement to write the line `\"Finished!\"` into `finished.txt`.\n23. Open the file `finished.txt` and append the line `\"Appending again!\"`.\n24. Create a dictionary, and write each key-value pair to a file (format: `key => value`).\n25. Print current working directory using `os.getcwd()` module.\n26. List files in the current directory with `os.listdir()`.\n27. Pass a file name to `os.listdir()`, then handle the error using `try/except`.\n28. After writing three lines to a file called `sample.txt`, read the file and print the number of lines. (Use `writelines()` and `readlines()`.)\n29. Use `seek` to skip the first 3 bytes then print the rest of the file.\n30. Catch any `OSError` when trying to open a file.\n\nSolutions: @sec-io-files-contexts-practice-problem-solutions-group-1\n\n### Group 2\n\n1. Read all lines from `data.txt` into a list, then write every second line to `even_lines.txt`.\n2. Write user input (entered with `input()`) to a file called `user.txt`.\n3. Open `data.txt` for writing and write 10 lines (`\"Line {i}\"`). Then, open the same file again and append a summary line: `\"Total lines: 10\"`.\n4. Write each character of a string to a new line in a text file.\n5. Ask for a filename. Try to read and print it, or print \"Not found!\" if the file does not exist.\n6. Write an integer list to a text file, then read it and compute their sum.\n7. Read up to the 10th character of a file and print those characters backwards.\n8. Write a file, then read its contents twice using `seek()`.\n9. Write three words to a file, each on their own line. Then, print all the lines of that file in uppercase.\n10. Write some lines to a file, including some empty lines. Then, read the file back, counting the number of empty lines.\n11. Write two lists (`genes` and `counts`) into a file as `gene,count` rows.\n12. Write some lines to a file, some of which contain the word `\"gene\"`. Then, open that file and print every line that contains the word `\"gene\"`.\n13. Read the contents from one file and write it uppercased to another file. (Read the input file line-by-line.)\n14. Try to open a file that doesn't exist without crashing the program.\n15. Create a list of dictionaries like this: `{\"A\": 1, \"B\": 2, \"C\": 3}`.  Then write the data as a CSV file with a header line.\n16. Create a small FASTA file. Then, read the file and count how many lines in a file start with \">\".\n17. Copy the header lines from the FASTA file you just created into another file.  Do not print the `>` in the output file.\n18. Write a few lines to a file. One of the lines should be `\"exit\"`.  Then, read the lines of the file you created, but stop as soon as you read the `\"exit\"` line.\n19. Open an output file, write one line, then print the output of `file.closed`. Next, use `with` to open the file, and after the block, print the result of `file.closed` again.\n20. Write three numbers to a binary file as bytes, then read, and print them as integers.\n\nSolutions: @sec-io-files-contexts-practice-problem-solutions-group-2\n\n### Group 3\n\n1. Using biopython, write code that opens a FASTA file and (1) prints the sequence ID and length for each sequence, and (2) prints the mean sequence length. (Use the FASTA sequence you created earlier.)\n2. Write the contents of a dictionary to a TSV file. Each line should be like `key\\tvalue`.  Then read the file, insert any lines where the value is greater than or equal to 10 into a new dictionary.\n3. Using pandas, create a data frame with the following data: `{\"A\": [1, 2, 3], \"B\": [4, 5, 6], \"C\": [7, 8, 9]}`, and write it to a CSV without the row index.  Read the resulting file using `csv.DictReader`.  Print any record in which the value in field \"A\" is >= 2 and the value in field \"C\" is <= 8.\n4. Write code that opens a FASTQ file, then prints the id and average quality score for the first 10 records.\n5. Read a binary file and print each byte in hexadecimal. (Use the built-in [hex()](https://docs.python.org/3/library/functions.html#hex) function.)\n6. Try to read and print the contents of a list of files. If any file doesn't exist, skip it and print a message about the file not being found.\n7. Write the given `gene_data` to a file.  Then, read the lines of the file, extracting gene names and sequences from each line using using regular expressions. Finally, print each gene name and sequence in the format \"name => sequence\".\n8. Create a file containing 50 random words chosen from the following list `[\"apple\", \"pie\", \"is\", \"good\"]`.  Read that file and count how many times each word occurs. Print the dictionary sorted by word count. Don't forget to set the random seed for reproducibility!\n9. Without using the CSV module, read a CSV file. If any of the lines have a different number of fields, stop the iteration and print an error message.\n10. Given a file path, open the file either as text or binary based on its extension (`.txt` -- text mode, `.bin` -- binary mode), and print the contents.  Make sure to handle file not found errors!\n\nSolutions: @sec-io-files-contexts-practice-problem-solutions-group-3\n\n",
    "supporting": [
      "io_files_contexts_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}